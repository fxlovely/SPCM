#!/bin/sh -e

##########################################################################
#   Script description:
#       
#   Arguments:
#       
#   Returns:
#       
#   History:
#   Date        Name        Modification
#   2015-06-16  root        Begin
##########################################################################

usage()
{
    printf "Usage: $0 hostname compute|io\n"
    exit 1
}


##########################################################################
#   Main
##########################################################################

if [ $# != 2 ] || [ 0$2 != 0'compute' ] && [ 0$2 != 0'io' ]; then
    usage
fi

long_node_name=$1
if ! echo $long_node_name | fgrep -q '.'; then
    printf "No domain name in $long_node_name.  Continue? y/[n] "
    read continue
    if [ 0$continue != 0y ]; then
	exit 1
    fi
fi
node_type=$2

node=${long_node_name%%.*}

case $node_type in
backup|compute|io)
    ;;
*)
    usage
esac

if [ -z EDITOR ]; then
    EDITOR="vi"
fi

conf_dir='/usr/local/cluster'

case `auto-ostype` in
RHEL)
    # FIXME: Prevent node from being enabled in the scheduler

    # Install basic tools and updates
    # cluster-init-node $long_node_name $node_type
    if ! ssh $node stat $conf_dir/init-done; then
	printf "You must run cluster-init-node $long_node_name first.\n"
	exit 1
    fi
    
    # Sync users
    printf "Sync users? [y]/n "
    read sync_users
    if [ 0$sync_users != 0n ]; then
	node-sync-all-users $node || true
    fi
    
    # Not in the UID range for normal cluster users, so node-sync-all-users
    # will skip it.
    # FIXME: Don't assume slurm
    node-sync-user $node slurm || true
    
    # Sync sys files
    cluster-sync-sysfiles $node
    
    cluster-sync-files $node
    
    # hosts.allow
    rsync -av /etc/hosts.allow ${node}:/etc
    
    # Other stuff
    
    # Sync software
    yum_list=/usr/local/cluster/$node_type-node-yum-packages
    if [ -e $yum_list ]; then
	printf "Installing local packages from $yum_list...\n"
	ssh $node yum install -y `cat $yum_list`
    else
	printf "No $yum_list found.\n"
    fi
    
    # Run cluster-setup compute
    # Do this last, since it enables the scheduler
    ssh -t $node cluster-setup $node_type
    
    printf "Be sure to wait until the node reboots before restarting SLURM.\n"
    ;;
*)
    # Install basic tools and updates
    # cluster-init-node $long_node_name $node_type
    if ! ssh $node stat $conf_dir/init-done; then
	printf "You must run cluster-init-node $long_node_name first.\n"
	exit 1
    fi
    
    # Sync users
    printf "Sync users? [y]/n "
    read sync_users
    if [ 0$sync_users != 0n ]; then
	node-sync-all-users $node || true
    fi
    
    # Not in the UID range for normal cluster users, so node-sync-all-users
    # will skip it.
    # FIXME: Don't assume slurm
    node-sync-user $node slurm || true
    
    # Sync sys files
    cluster-sync-sysfiles $node
    
    cluster-sync-files $node
    
    # hosts.allow
    rsync -av /etc/hosts.allow ${node}:/etc
    
    # Other stuff
    
    # Sync software
    # FIXME: Implement for FreeBSD
    
    # Run cluster-setup compute
    # Do this last, since it enables the scheduler
    ssh -t $node cluster-setup $node_type
    
    printf "Be sure to wait until the node reboots before restarting SLURM.\n"
    ;;
esac

# FIXME: Support other schedulers
scontrol update nodename=$node state=resume

