#!/bin/sh -e

##########################################################################
#   Description:
#       Automate setup of a simple FreeBSD cluster.
#       Installs common software and configures settings to facilitate
#       cluster operation.  Assumes a single head node will handle
#       job initiation/scheduling and act as a file server for all nodes.
#
#   Usage:
#       First, run 
#
#           cluster-setup head
#
#       on the head node.
#
#   Then, run
#
#           cluster-setup compute
#
#       on the rest.
#       
#   History:
#       Dec 2009    J Bacon
##########################################################################


usage()
{
    printf "Usage: $0 head|compute\n"
    exit 1
}


line()
{
    printf "==============================================================================\n"
}


pause()
{
    local junk
    printf "Press enter to continue..."
    read junk
}


##########################################################################
#   Function description:
#       
#   Arguments:
#       
#   Returns:
#       
#   History:
#   Date        Name        Modification
#   2013-12-03  Charlie &   Begin
##########################################################################

stop_service()
{
    if [ $# != 1 ]; then
	printf "Usage: stop_service service\n"
    fi
    service $1 stop > /dev/null 2>&1 || true
    sleep 2
    killall $1 > /dev/null 2>&1 || true
    sleep 1
    killall -9 $1 > /dev/null 2>&1 || true
}


##########################################################################
#   Description:
#       Install ports or packages specified by arguments if they are not
#       already installed.  If $AUTO_BUILD_FROM_SOURCE is true, installs from source,
#       otherwise attempts to install using pkg add.
#
#   Arguments:
#       List of ports in the for "category/name"
##########################################################################

install_packages()
{
    printf "Installing:\n"
    for pkg in $*; do
    {
	printf "\t$pkg...\n"
	if [ ! -e $LOG_DIR ]; then
	    mkdir $LOG_DIR
	fi
	log_file=$LOG_DIR/`echo $pkg | tr / -`
	if ! auto-install-packages -l $pkg > $log_file 2>&1; then
	    more $log_file
	    exit 1
	fi
    }
    done
}


install_port()
{
    local resp category port
    
    if [ $# -lt 2 ]; then
	printf "Usage: install_port category port [make flags]\n"
	exit 1
    fi
    
    category=$1
    port=$2
    shift
    shift
    
    # FIXME: Use cluster-pkgdir
    cd /usr/ports/$category/$port
    make deinstall
    make clean
    make rmconfig
    make reinstall
}


add_node_name()
{
    if [ $# != 2 ]; then
	printf "Usage: $0 node-name node-file\n"
	exit 1
    fi
    
    name=$1
    file=$2
    
    # Prevent fgrep from failing
    if [ ! -e $file ]; then
	touch $file
    fi
    
    if ! fgrep -q $name $file; then
	printf "$name\n" >> $file
    fi
}


install_scheduler()
{
    line
    install_packages sysutils/slurm-wlm
    pw usermod slurm -d /home/slurm -m
}


install_mpi()
{
    line
    # Install OpenMPI from source so we can choose build options
    if ! auto-package-installed net/openmpi; then
	printf "\nInstalling openmpi...\n"
	install_packages net/openmpi
    fi
}


slurm_config()
{
    # FIXME: creating these directories should not be necessary
    # --syslog?
    mkdir -p /var/log/munge /var/run/munge /var/lib/munge
    mkdir -p /var/log/slurm /var/run/slurm
    chown slurm:slurm /var/log/slurm /var/run/slurm
    
    # Generate munge.key
    $LOCALBASE/etc/rc.d/munged stop > /dev/null 2>&1 || true
    munge_dir="$LOCALBASE/etc/munge"
    if [ $NODE_TYPE == 'head' ]; then
	if [ ! -e $munge_dir/munge.key ]; then
	    mkdir -p -m 0700 $munge_dir
	    touch $munge_dir/munge.key
	    chmod 400 $munge_dir/munge.key
	    printf "Generating munge key...\n"
	    dd if=/dev/random bs=1 count=1024 > $munge_dir/munge.key
	fi
    fi
    
    # Enable munge
    auto-enable-service munged $0 > $LOG_DIR/munged_enable 2>&1
    service munged restart

    slurm_conf="$LOCALBASE/etc/slurm.conf"
    if [ $NODE_TYPE = 'head' ]; then
	line
	cat << EOM

If you have a slurm.conf file prepared, restore it to $LOCALBASE/etc now.

After you press return, slurm.conf will be opened in $EDITOR.

You can also generate a SLURM config file using the web wizard at:

    $LOCALBASE/share/doc/slurm-*/html/configurator.html

The slurmctld daemon will be started after you exit the editor.

EOM
	line
	pause
	if [ ! -e $slurm_conf ]; then
	    cp $slurm_conf.example $slurm_conf
	fi
	$EDITOR $slurm_conf
	stop_service slurmctld
	auto-enable-service slurmctld $0 > $LOG_DIR/slurmctld_enable 2>&1
	service slurmctld restart
    else
	stop_service slurmd
	auto-enable-service slurmd $0 > $LOG_DIR/slurmd_enable 2>&1
	service slurmd restart
    fi
}


scheduler_config()
{
    line
    if auto-package-installed sysutils/slurm-wlm; then
	slurm_config
    fi
    printf "Done with slurm_config.\n"
    
    if auto-package-installed sysutils/condor; then
	if [ ! -e $LOCALBASE/etc/condor_config ]; then
	    cp $LOCALBASE/etc/condor/condor_config $LOCALBASE/etc
	fi
	if [ ! -e $LOCALBASE/etc/condor_config.local ]; then
	    cp $LOCALBASE/etc/condor/condor_config.local $LOCALBASE/etc
	fi
	cat << EOM

If you have condor_config and condor_config.local files prepared, restore
them to $LOCALBASE/etc now.

EOM
	pause
	$EDITOR $LOCALBASE/etc/condor_config*
    fi
}


nfs_config()
{
    cat << EOM

Some schedulers require a shared spool or config directory.  Check the
documentation for your scheduler before deciding which directories to
share via NFS.

Some other directories you may want to share include:

    /usr/home (or /home)
    /var/cache/pkg

EOM

    line
    nfs_config=`auto-ask nfs-config 'Configure NFS?' y`
    if [ $nfs_config != 'y' ]; then
	return
    fi

    # FIXME: Submit PR
    # NFS may fail to start without this, even if using ZFS
    touch /etc/exports
    
    auto-enable-service -s statd rpc_statd $0
    auto-enable-service -s lockd rpc_lockd $0
    
    case $NODE_TYPE in
    "head"|"io")
	# Configure NFS whether or not compute nodes will use it
	# Export /usr (which should include /usr/home)
	# FIXME: Make sure NFS server is enabled in rc.conf first
	# Does not work for multi-homed host
	# ip=`fgrep $head_host $HOSTS | awk ' { print $1 }' | uniq`
	subnet=`auto-ask subnet "\nSubnet for NFS?" 192.168.0.0`
	
	share='x'
	while [ 0$share != 0 ]; do
	    line
	    printf "\nMounted filesystems:\n\n"
	    df
	    printf "\nCurrent mounts:\n\n"
	    showmount -e
	    printf "\nDirectory to export? [Press enter to quit] "
	    read share
	    
	    if [ 0$share != 0 ]; then
		# FIXME: Add support for ZFS
		fs_type=`mount | awk '$3 == "/usr/home" { print $4 }'`
		if [ $fs_type == '(zfs,' ]; then
		    zfs_share=`mount | awk '$3 == "/usr/home" { print $1 }'`
		    zfs set sharenfs="-maproot=root -network $subnet -mask $NETMASK" $zfs_share
		else
		    printf "Updating /etc/exports...\n"
		    auto-append-line "$share\t-maproot=0\t-network $subnet -mask $NETMASK\n" /etc/exports $0
		fi
	    fi
	done
	zfs get sharenfs
	
	printf "Updating $RC_CONF...\n"
	# Need UDP for some PXE ROMs
	auto-append-line 'nfs_server_flags="-t -u -n 16"' $RC_CONF $0
	auto-enable-service nfs_server $0 > $LOG_DIR/nfsd_enable 2>&1
	service nfsd restart
	killall -HUP mountd
	printf "\nYou may need to reboot before NFS clients can mount the new shared folder.\n\n"
	pause
	;;
	
    *)
	;;
    esac
	
    case $NODE_TYPE in
    "compute"|"io")
	fstab=/usr/local/cluster/fstab.$NODE_TYPE
	if [ -e $fstab ]; then
	    printf "Automatically adding shares from $fstab...\n"
	    while read mount; do
		dir=`echo $mount | awk '{ print $2 }'`
		if fgrep -qw $dir /etc/fstab; then
		    printf "$dir is already in fstab.\n"
		else
		    printf "Adding $dir to fstab...\n"
		    printf "$mount\n" >> /etc/fstab
		    mkdir -p $dir
		fi
	    done < $fstab
	else
	    host='x'
	    while [ 0$host != 0 ]; do
		df
		printf "\nHost name of NFS server? [Press enter to quit] "
		read host
		
		if [ 0$host != 0 ]; then
		    printf "Directory to mount from $host? "
		    read share
		    
		    printf "Local mount point? [$share] "
		    read mount
		    if [ 0$mount = 0 ]; then
			mount=$share
		    fi
		    
		    # Unmount local if necessary
		    # First try ZFS
		    zfs_ds=`zfs list | awk -v share=$share '$5 == share { print $1 }'`
		    if [ 0$zfs_ds != 0 ]; then
			zfs set mountpoint=none $zfs_ds
		    fi
		    # Not a ZFS mount?  Maybe some other FS.
		    if mount | fgrep $share; then
			umount $share
		    fi
		    
		    # Configure shared directory
		    found=`awk '$1 == "'${head_host}:$share'" { print $1 }' /etc/fstab`
		    if [ 0$found = 0 ]; then
			printf "\nUpdating /etc/fstab...\n\n"
			printf "# Generated by $0.\n" >> /etc/fstab
			printf "# Adjust rsize and wsize if needed to improve performance.\n" >> /etc/fstab
			printf "${head_host}:$share\t\t$mount\tnfs\trw,intr,noatime\t0\t0\n" >> /etc/fstab
		    else
			printf "Remote filesystem $head_host:$share already configured.\n"
		    fi
		    mkdir -p $share
		fi
	    done
	fi
	mount -a
	;;
	
    *)
	;;
    esac
}


ganglia_config()
{
    ##########################################################################
    #   Head node: bind in both send and receive?
    #   Compute nodes: host = head IP
    ##########################################################################
    
    if [ $NODE_TYPE = "head" ]; then
	# Install apache
	line
	printf "Configuring apache...\n"
	if ! auto-package-installed www/$APACHE_PKG; then
	    install_packages www/$APACHE_PKG
	    pause
	fi

	if [ ! -e $LOCALBASE/etc/$APACHE_PKG/httpd.conf.orig ]; then
	    printf "Patching httpd.conf...\n"
	    mv $LOCALBASE/etc/$APACHE_PKG/httpd.conf \
		$LOCALBASE/etc/$APACHE_PKG/httpd.conf.orig
	    awk -f $DATADIR/patch-apache.awk \
		$LOCALBASE/etc/$APACHE_PKG/httpd.conf.orig \
		> $LOCALBASE/etc/$APACHE_PKG/httpd.conf
	fi
	
	# Install a rudimentary home page
	if [ ! -e $LOCALBASE/www/$APACHE_PKG/data/global_styles.css ]; then
	    cp $DATADIR/WWW/* $LOCALBASE/www/$APACHE_PKG/data
	    sed -i '' -e "s|%%HOSTNAME%%|$(hostname)|g" \
		$LOCALBASE/www/$APACHE_PKG/data/index.php
	fi
	
	line
	# Install ganglia web frontend
	if ! auto-package-installed sysutils/ganglia-webfrontend; then
	    install_packages sysutils/ganglia-webfrontend
	fi
	
	# Should be pulled in by ganglia-webfrontend, but they're not
	# Needed for Apache
	install_packages lang/php5 www/mod_php5
	
	# FIXME: Dying here on first run
	# Must come after php5 install, since http.conf was patched
	auto-enable-service $APACHE_PKG cluster-setup \
	    > $LOG_DIR/${APACHE_PKG}_enable 2>&1
	service $APACHE_PKG reload
	
	# Add date_default_timezone_set('America/Chicago'); to ganglia.php
	# or update date.timezone in $LOCALBASE/etc/php.ini and restart
	# Apache
	if [ ! -e $LOCALBASE/etc/php.ini ]; then
	    cp $LOCALBASE/etc/php.ini-production $LOCALBASE/etc/php.ini
	fi
	
	# Set timezone if not already set
	if ! grep -q '^date.timezone' $LOCALBASE/etc/php.ini; then
	    printf "Time zone? (Example: America/Chicago) "
	    # FIXME: Find a way to validate input
	    read zone
	    sed -i '.orig' -e "s|;date.timezone =|date.timezone = $zone|g" \
		$LOCALBASE/etc/php.ini
	fi

	# patch creates gmetad.orig
	sed -i '' \
	    -e 's|my cluster|all nodes|g' \
	    -e 's|# gridname "MyGrid"|gridname "%%SHORT_HOSTNAME%%"|g' \
	    -e 's|# trusted_hosts 127.0.0.1 169.229.50.165 my.gmetad.org|trusted_hosts 127.0.0.1 %%LOCAL_IP%% %%LONG_HOSTNAME%%|g' \
	    $LOCALBASE/etc/gmetad.conf
	
	# Configure ganglia
	if grep -q '%%SHORT_HOSTNAME%%' $LOCALBASE/etc/gmetad.conf; then
	    # FIXME: gmetad crashes if COMPUTE_NODE_LIST is too long
	    sed -i '' -e "s|%%SHORT_HOSTNAME%%|$(hostname -s)|g" \
		      -e "s|%%LONG_HOSTNAME%%|$(hostname)|g" \
		      -e "s|%%LOCAL_IP%%|$HEAD_IP|g" \
		$LOCALBASE/etc/gmetad.conf
	fi

	line
	stop_service $APACHE_PKG
	service $APACHE_PKG restart
    fi
    
    line
    if ! auto-package-installed sysutils/ganglia-monitor-core; then
	install_packages sysutils/ganglia-monitor-core
    fi
    
    if grep -q 'name = "unspecified"' $LOCALBASE/etc/gmond.conf; then
	if [ $NODE_TYPE = head ]; then
	    name=$(hostname -s)
	else
	    name=$head_host
	fi
	sed -i '.orig' \
	    -e "s|name = \"unspecified\"|name = \"$name\"|g" \
	    $LOCALBASE/etc/gmond.conf
    fi
    
    
    stop_service gmond
    auto-enable-service gmond cluster-setup \
	> $LOG_DIR/gmond_enable 2>&1
    service gmond restart
    
    if [ $NODE_TYPE = "head" ]; then
	stop_service gmetad
	auto-enable-service gmetad cluster-setup \
	    > $LOG_DIR/gmetad_enable 2>&1
	service gmetad restart
    fi
}


##########################################################################
#   Function description:
#       Add this host to authorized_hosts on remote host
#
#   Arguments:
#       1) remote host
#       
#   History:
#   Date        Name        Modification
#   2013-03-01  Charlie &   Begin
##########################################################################

ssh_authorize()
{
    if [ $# -lt 1 ] ; then
       echo "usage: ssh-authorize remotehost"
       exit 1
    fi
    remotehost=$1
    
    cd
    
    user=`whoami`
    echo "Authorizing ${user}@${HOST} on $remotehost."
    ssh $remotehost 'umask 077; mkdir -p .ssh'

    # See if key already exists on remote host
    if ssh $remotehost "grep -q ${user}@${HOST} .ssh/authorized_keys"; then
	printf "Key already exists for this host.\n"
	return
    fi
    
    #
    # If a key hasn't been generated then do it.
    #
    if [ ! -f .ssh/id_rsa.pub ] ; then
	printf "Error: ssh_authorize must be called AFTER id_rsa is installed.\n"
	exit 1
    fi
    
    key=`cat .ssh/id_rsa.pub`
    ssh $remotehost "echo $key >> .ssh/authorized_keys ; chmod 600 .ssh/authorized_keys"
}


##########################################################################
#   Function description:
#       
#   Arguments:
#       
#   Returns:
#       
#   History:
#   Date        Name        Modification
#   2012-07-30  Charlie &   Begin
##########################################################################

ssh_config()
{
    # Verify that nfs_config has been run

    line
    printf "Configuring ssh...\n"
    
    # Permit root login over ssh
    if ! grep -iq '^PermitRootLogin without-password' /etc/ssh/sshd_config; then
	sed -i ".bak" 's|#PermitRootLogin no|PermitRootLogin without-password|g' /etc/ssh/sshd_config
	# killall -HUP sshd
	service sshd reload
	line
	cat << EOM

WARNING: 'PermitRootLogin without-password' has been enabled.

This is necessary for clusters that use keyed SSH between nodes for system
activities.  If you are concerned about security, you can manually
reconfigure the head node.

EOM
    fi
    
    # All nodes should already accept passwordless login from the head node
    # This is set up by auto-pxe-installer-setup and left to the user
    # is they are not using it.
    if [ $NODE_TYPE = 'head' ]; then
	# Disable prompting for new hosts, etc.
	cluster-update-ssh_config
    fi
}


##########################################################################
#   Function description:
#       Must be done after NFS config due to use of $HEAD_USR.
#
#   Arguments:
#       
#   Returns:
#       
#   History:
#   Date        Name        Modification
#   2012-07-30  Charlie &   Begin
##########################################################################

resource_limits()
{
    # Set resource limits
    line
    printf "Configuring resource limits...\n"
    if [ ! -e /etc/login.conf.orig ]; then
	cp /etc/login.conf /etc/login.conf.orig
    fi

    cat << EOM
Setting desired resource limits in /etc/login.conf.

It is a good idea to limit vmemoryuse and maxproc on the head node
to prevent it from being overloaded by careless users.

The scheduler should manage limits on compute nodes, but some generous hard
limits on vmemoryuse and maxproc in login.conf can help protect nodes from
fork() bombs and memory leaks that the scheduler does not catch (fast enough).
Usually, something like 10 + the number of cores is a good limit for compute
nodes.

EOM
    # default_maxproc=$(( `sysctl -n kern.smp.cpus` * 2 ))
    default_maxproc=32
    maxproc=`auto-ask max-proc "Max processes for the $NODE_TYPE node?" $default_maxproc`
    
    default_vmem=$(( `sysctl -n hw.realmem` / 1024 / 1024 ))m
    vmem=`auto-ask vmem "Max memory use for the $NODE_TYPE node? (use 'm' or 'g' suffix)" $default_vmem`
    
    umask=`auto-ask umask "umask for the $NODE_TYPE node?" 027`
    sed -i '' -e "s/maxproc=unlimited/maxproc=$maxproc/g" \
	     -e "s/vmemoryuse=unlimited/vmemoryuse=$vmem/g" \
	     /etc/login.conf
    cap_mkdb /etc/login.conf
    auto-set-umask $umask
}


##########################################################################
#   Function description:
#       
#   Arguments:
#       
#   Returns:
#       
#   History:
#   Date        Name        Modification
#   2013-02-15  Charlie &   Begin
##########################################################################

update_system()
{
    line
    printf "Updating system clock...\n"
    stop_service ntpd
    ntpdate -u pool.ntp.org
    auto-enable-service ntpd cluster-setup > /dev/null 2>&1
    service ntpd restart
}


##########################################################################
#   Function description:
#       
#   Arguments:
#       
#   Returns:
#       
#   History:
#   Date        Name        Modification
#   2013-12-02  Jason Bacon Begin
##########################################################################

install_common_tools()
{
    # Quick-install some common tools
    line
    install_packages devel/gmake net/rsync converters/libiconv \
	editors/nano ftp/wget devel/subversion \
	shells/bash shells/dash
    yes | pkg install -y bsdstats
}


##########################################################################
#   Function description:
#       
#   Arguments:
#       
#   Returns:
#       
#   History:
#   Date        Name        Modification
#   2013-12-02  Jason Bacon Begin
##########################################################################

get_port_install_method()
{
    line
    #resp=`auto-ask use-source "Build ports from source?" n`
    resp=n
    if [ 0$resp = 0'y' ]; then
	export AUTO_BUILD_FROM_SOURCE='yes'
    else
	export AUTO_BUILD_FROM_SOURCE='fall-back'
	if [ x$AUTO_PACKAGEROOT = x ]; then
	    printf "Finding fastest mirror... "
	    export AUTO_PACKAGEROOT=`auto-fastest-mirror`
	    printf "$AUTO_PACKAGEROOT\n"
	fi
    fi
}


##########################################################################
#   Function description:
#       
#   Arguments:
#       
#   Returns:
#       
#   History:
#   Date        Name        Modification
#   2013-12-02  Jason Bacon Begin
##########################################################################

startup_scripts()
{
    # Install extra login logic
    line
    printf "Installing startup scripts...\n"
    if [ ! -e $LOCALBASE/cluster/profile ]; then
	cp $DATADIR/profile $LOCALBASE/cluster
    fi
    if [ ! -e $LOCALBASE/cluster/csh.login ]; then
	cp $DATADIR/csh.login $LOCALBASE/cluster
    fi
    auto-append-line cluster/profile ". $LOCALBASE/cluster/profile" /etc/profile cluster-setup
    auto-append-line cluster/csh.login "source $LOCALBASE/cluster/csh.login" /etc/csh.login cluster-setup
}


##########################################################################
#   Function description:
#       
#   Arguments:
#       
#   Returns:
#       
#   History:
#   Date        Name        Modification
#   2013-12-02  Jason Bacon Begin
##########################################################################

enable_procfs()
{
    line
    auto-enable-procfs
}


##########################################################################
#   Function description:
#       
#   Arguments:
#       
#   Returns:
#       
#   History:
#   Date        Name        Modification
#   2013-12-02  Jason Bacon Begin
##########################################################################

reboot_maybe()
{
    line
    cat << EOM

You must reboot to test the new configuration.  If this is the first time
you completed the cluster-setup $NODE_TYPE process, you should reboot now.

EOM

    printf "Reboot? (y/[n]) "
    read reboot
    if [ 0$reboot = 0y ]; then
	shutdown -r now
    fi
}


##########################################################################
#   Function description:
#       
#   Arguments:
#       
#   Returns:
#       
#   History:
#   Date        Name        Modification
#   2015-01-30  Charlie &   Begin
##########################################################################

get_head_host()
{
    if [ $NODE_TYPE = "compute" ]; then
	# If cluster-setup was previously completed on this node,
	# get head node from configuration, otherwise ask.
	head_host=''
	while [ 0$head_host = 0 ]; do
	    head_host=`auto-ask head-hostname "\nShort hostname of head node?" login`
	done
    else
	head_host=`hostname -s`
	hostname -s > $LOCALBASE/cluster/head_node
    fi
}


##########################################################################
#   Main
##########################################################################

if [ $# != 1 ]; then
    usage $0
fi

case $1 in
head|compute)
    ;;
*)
    usage $0
    ;;
esac

if [ `whoami` != root ]; then
    printf "$0 must be run as root.\n"
    exit 1
fi

for file in /root/ssh /etc/fstab; do
    if [ -e $file ] && [ ! -e $file.backup ]; then
	printf "Backing up $file...\n"
	cp -R $file $file.backup
    fi
done

##########################################################################
#   Set common variables
##########################################################################

# Recommended layout for dedicated hardware:
# Use netmask of 255.255.128.0.
MAX_NODES=60000

# Misc
LOCALBASE=/usr/local
RC_CONF=/etc/rc.conf
HOSTS=/etc/hosts
HOSTS_ALLOW=/etc/hosts.allow
START_DIR=`pwd`
APACHE_PKG=apache24

# Used by child scripts, so export it
LOG_DIR=$START_DIR/cluster-setup-log
line
printf "Command output will be stored in $LOG_DIR.\n"
line

# Source for default files
DATADIR=$LOCALBASE/share/cluster-admin

# Needed by openjdk, bash, etc.
auto-add-fdesc-mount

NODE_TYPE=$1
case $NODE_TYPE in
"head"|"compute")
    ;;
*)
    printf "Invalid installation type: $NODE_TYPE\n"
    usage $0
esac

# Config files used by cluster-admin
if [ $NODE_TYPE = head ]; then
    CLUSTER_DATA="$LOCALBASE/cluster"
    mkdir -p $CLUSTER_DATA

    if [ -z $EDITOR ]; then
	EDITOR=vi
	export EDITOR
    fi
    
    printf "\nIf you have an old $HOSTS_ALLOW to restore, do it now.\n\n"
    pause
    $EDITOR $HOSTS_ALLOW
fi

HEAD_IP=`auto-ask head-ip '\nIP address of head node LOCAL interface?' 192.168.0.2`
NETMASK=`auto-ask netmask 'Netmask for local network?' 255.255.128.0`

##########################################################################
#   Begin setup
##########################################################################

if [ $NODE_TYPE = head ]; then
    latest=`auto-ask latest "Use latest packages instead of quarterly?" y`
    if [ $latest = y ]; then
	mkdir -p $LOCALBASE/etc/pkg/repos
	cat << EOM > $LOCALBASE/etc/pkg/repos/FreeBSD.conf
FreeBSD: {
  url: "pkg+http://pkg.FreeBSD.org/\${ABI}/latest"
}
EOM
    fi
fi

# The following configuration must be done on all nodes, although
# different node types may be configured differently.
update_system               # Start with and NTP update
enable_procfs               # Needed for?
get_port_install_method     # Build ports from source?
install_common_tools        # gmake, etc.
get_head_host
install_scheduler           # Select and install a scheduler
nfs_config                  # Set up head node NFS server.
ssh_config                  # Enable keys between nodes. After nfs_config.
scheduler_config            # Configure scheduler.  After ssh_config.
resource_limits             # Configure login.conf.  After nfs_config.
ganglia_config              # Cluster monitoring.

# Configuration steps that only occur on certain node types
case $NODE_TYPE in
"head")
    startup_scripts
    cluster-update-all-ssh_config
    ;;

"compute")
    # Install after scheduler.  OpenMPI port has options for scheduler
    # integration.
    install_mpi
    ;;
*)
    ;;
esac

if [ $NODE_TYPE = head ]; then
    printf "Checking/setting UID limits...\n"
    cluster-lowest-uid
    cluster-highest-uid
fi

# Required by cluster-ssh-keygen, called from cluster-adduser
# FIXME: Remove need for sudo.  Maybe use su -m?
install_packages security/sudo

if ! fgrep -q clusteradmin /etc/passwd; then
    cat << EOM

Adding clusteradmin user...

EOM
    cluster-groupadd clusteradmin -g 1000 || true
    cluster-useradd clusteradmin 1000 clusteradmin 'Cluster Administrator' /bin/tcsh || true
fi

# Reboot to test new config after initial setup
reboot_maybe
